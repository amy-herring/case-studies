---
title: Causal Inference
output: 
  revealjs::revealjs_presentation:
    theme: night
    highlight: espresso
    center: true
    transition: none
    css: styles.css
    fig_caption: true
    reveal_options:
      progress: true
      slideNumber: true
      
  
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width=6, fig.height=5)
```



## Causality

Birthweight is a commonly-used indicator of a newborn infant's health status. Because this indicator is easily obtained, it is a critical component of population health reporting by the World Health Organization and governments around the globe.

Can we learn whether a factor may *cause* the increase or decrease in birthweight?


## Correlation does not imply causation 
* A lot of research questions in statistics/machine learning are causal in nature
* Standard statistical analysis aims to infer 'associations' among variables
* Causal analysis aims to infer aspects of the data generating process
  * Requires randomized experiments or causal assumptions 

## Correlation does not imply causation 
```{r , echo=FALSE, fig.cap="", out.width = '100%'}
knitr::include_graphics("figures/tylervigen.png")
```

  
## Randomization

*Randomization* is a powerful technique in statistics that is used to make two (or more) groups of interest comparable. 

For example, suppose that students in Duke's Master of Arts in Teaching program develop an innovative new math curriculum and that the program will be launched in area public schools. 
If each school has the ability to choose (or not) the new curriculum, we might worry that the schools with smarter students, better teachers, more children of math professors, or even that are desperate to increase test performance might be more likely to adopt the new curriculum. Random allocation of schools to treatment, however, should alleviate these concerns by equally distributing schools with these characteristics across the curricula under study.

## Confounding

Smarter students, better teachers, etc. are considered potential *confounding* factors because they may be related to a school's decision to adopt the new curriculum and to student performance.  If schools with better students and teachers are more likely to adopt the new curriculum, and those schools have better performance, then we cannot be sure whether the performance is related to the new curriculum itself or to the qualities of the students and teachers in the schools that chose the new curriculum.

## Confounding
* Let $W$ denote treatment/exposure, $Y$ outcome, and $X$ potential confounder
* A *confounding* variable influences the association of treatment and outcome
    + Example: W: birth order, Y: Trisomy 21 status, X: maternal age
```{r , echo=FALSE, fig.cap="", out.width = '50%'}
knitr::include_graphics("figures/causal_diagram.png")
```
* A study finds that children born 5th or higher in their families have a 4-fold increased risk of Trisomy 21. Is this association causal or due only to maternal age, which is related to birth order and Trisomy 21 risk?
* We will aim to address observed confounders through causal inference frameworks.
* If a confounder is not observed, we may not be able to adjust for it!

## Causal inference advantages and drawbacks

* Causal inference frameworks attempt to make more transparent assumptions that are necessary for valid inference

* Use of a causal inference framework alone does not produce valid inferences (e.g., you can mess up with any model or framework!)

## Frameworks for causal inference
* Potential outcome framework also known as counterfactual framework or Neyman-Rubin Causal Model (RCM)

* 3 Integral components to RCM:
       1. Potential outcomes corresponding to the levels of the treatment ($Y(1)$, $Y(0)$) - only one is ever observed
       2. Assignment mechanism (how is treatment assigned to observations? e.g. random assignment)
       3. Outcome model relating potential outcomes and covariates
       
* Sketch on prior slide illustrates the causal diagram framework by Pearl using a directed acyclic graph (DAG)


## Causal Assumptions 
To identify causal effects from observed data, we must make assumptions. Two important ones are:
 
1. No interference - potential outcome for an individual cannot depend on what treatment other people receive (e.g. vaccinations)
2. No different versions of the treatment (e.g. surgery performed by different surgeons - may provide slightly different versions of the treatment)

## Causal Assumptions cont.
  * **Assignment mechanism**: the probabilistic rule that decides which unit gets assigned to which treatment
  
      + In randomized experiments, assignment mechanism is *known* and *controlled* by investigators.
      + In observational studies, assignment mechanism is *unknown* and *uncontrolled*.
  * Properties of assignment mechanism:
      1. Individualistic assignment: treatment assignment for unit $i$ does not depend on outcomes and assignments for other units
      2. Probabilistic assignment: probability of assignment to treatment is strictly between 0 and 1
        + Every unit has some probability of getting the treatment
      3. Unconfounded Assignment: assignment does not depend on the potential outcomes

## Average treatment effect
Under these assumptions, we can estimate the

Average Treatment Effect (ATE) $$ \tau = \mathbb{E}[Y_i(1) - Y_i(0)]$$

Where $Y_i(1)$ is the response you would get for person $i$ under condition 1, and $Y_i(0)$ is the response you would have seen for that person if instead they experienced condition 0.  Of course you only actually see one condition for each person.


## Quick start to using causal inference
In oberservational studies, we must adjust for the measured confounding. One way to do this is by including measured confounders in a model. This works well if there are not too many confounders. *Propensity score* methods are another choice and are particularly attractive when we may have many confounders relative to the sample size.

The idea behind these methods is to compare two groups of people who have different values of the treatment but similar values of the measured confounders $X$, in hopes that balancing comes close to random allocation of the treatment.
  


## Propensity Score Methods
A *propensity score* is defined as the conditional probability of receiving the treatment given the pre-treatment covariates $X$:
$$ e(X) = Pr(W=1|X) = \mathbb{E}(W|X) $$

Propensity scores can balance the distribution of all $X$ between treatment groups: 
$$ W \perp X | e(X)$$
  
  * $e(X)$ is a summary score of the observed covariates
  * We can use this lower-dimensional summary score of the covariates to perform causal inference through stratification, matching, weighting, etc.
  
##Propensity score analysis of causal effects
Propensity score analysis (for observational studies) typically involves two stages:

1. Estimate the propensity score (e.g., using logistic regression)
2. Given the estimated propensity score, estimate the causal effects through one of these methods:
    1. Subclassification
    2. Weighting
    3. Matching
    4. Regression
    5. Mixed procedure of the above
    
```{r openmatching,results='hide'}
library(Matching)
```
    
## National Supported Work Demonstration (NSW)

The NSW was a US-federally-funded project designed to provide 12-18 months of work experience to people who had faced economic and social problems. 

In this study, the outcome was income in 1978 (after program participation). Comparing participants to non-participants, researchers found the participants had higher income. Does that mean the program worked?

## National Supported Work Demonstration (NSW)

```{r lalondehist,out.width='50%'}
data(lalonde)
hist(lalonde$re78, main="1978 Earnings", sub="(1978 US Median Income: 15000)",
     xlab="Earnings") #yikes, zero-inflated
```


## National Supported Work Demonstration (NSW)
```{r simple}
c(mean(lalonde$re78[lalonde$treat==1]==0),mean(lalonde$re78[lalonde$treat==0]==0)) 
c(mean(lalonde$re78[lalonde$treat==1]),mean(lalonde$re78[lalonde$treat==0]))
wilcox.test(lalonde$re78~lalonde$treat)
```

## Does this mean the program worked?

One concern in evaluating the program is whether program participants (indicator variable treat=1) differ from non-participants across a variety of factors, including age, race and ethnicity, marital status, high school graduation status, and income in 1974.

## Logistic regression

*Logistic regression* is a type of generalized linear model, which generalizes the typical linear model to non-Gaussian data. The logistic regression model is linear on the log of the odds: $$\log\frac{p_i}{1-p_i}=\beta_0+\beta_1x_{1i}+\cdots+\beta_px_{pi},$$ where $p_i=Pr(y_i=1)$.
If the parameter $\beta_j>0$, then increasing levels of $x_j$ are associated with higher probabilities that $y=1$, and values of $\beta_j<0$ are associated with lower probabilities that $y=1$. $\beta_j=0$ is consistent with no association between $x_j$ and $y$.

## NSW participants

If NSW program participants are similar to comparison people in the data set, then we would expect a logistic regression model for the probability of being a NSW participant to have $\beta$ coefficients that are not significantly different from 0 (except for the intercept, which is related to the overall fraction of people in the study who participated in NSW). This is easily evaluated in R.

## Are NSW participants similar to nonparticipants?

```{r logistic}
glm1  <- glm(treat~age + black +hisp + married + nodegr + re74, family=binomial, 
    data=lalonde)
summary(glm1)
```

## Are NSW participants similar to nonparticipants?

Based on this model, people without high school degrees were less likely to be in the NSW program than their counterparts who graduated high school. However, people who participated were similar than nonparticipants in terms of the other factors. Maybe incomes were higher among program participants simply because program participants were more likely to have high school diplomas.

## Causal analysis

Let's walk through the steps to perform a propensity score causal analysis of the jobs program.

 * We will consider treatment $W$ to be program participation
 * Outcome is 1978 income
 
We want to know if program participation led to increased income in 1978.

## Stage 1: Estimate the propensity score
Aim of using propensity scores is to ensure **overlap** and **balance** of covariates between treatment groups.

1. For binary treatments, fit propensity score model via logistic regression (we already did this!)

```{r propmodel, eval=FALSE}
glm1  <- glm(treat~age + black +hisp + married + nodegr + re74, family=binomial, 
    data=lalonde)
```
Next, estimate propensity scores
```{r}
ps <- predict(glm1, type="response")
summary(ps)
```

## Stage 1: Estimate the propensity score
Check overlap of propensity scores between treatment groups, and discard observations with non-overlapping propensity scores so that the groups look similar in terms of variables in our model
  
```{r, echo=FALSE, out.width='60%'}
par(mfrow=c(1,2))
hist(ps[which(lalonde$treat==1)], col=2, xlab="NSW",ylim=c(0,150),xlim=c(0.2,0.7),main="")
hist(ps[which(lalonde$treat==0)], col=3, xlab="not NSW",ylim=c(0,150),xlim=c(0.2,0.7),main="")

```

## Stage 1: Estimate the propensity score

Next discard those units that aren't in the overlapped region
```{r}
ps_0 <- ps[which(lalonde$treat==0)]
ps_1 <- ps[which(lalonde$treat==1)]
overlap_ind <- which(ps < max(ps_0) & ps > min(ps_1))
ps_overlap = ps[overlap_ind]
lalonde_overlap = lalonde[overlap_ind,]
dim(lalonde); dim(lalonde_overlap)
```
In this case, there was a good bit of overlap, so very few observations were discarded.

## Stage 1: Estimate the propensity score
Assess balance of the covariates based on the propensity scores

1. Create K blocks of $\widehat{e}$ based on its quantiles
      
```{r blocks}
      blocks = cut(ps_overlap, quantile(ps_overlap, probs=seq(0,1,by=.2)), 
      labels=c(1:5), include.lowest=TRUE)
```

For every covariate, we then assess the balance within **each of the blocks**, e.g. by a t-test or $\chi^2$ test
      
## Assessing balance: continuous variables      

```{r balancecontinuous, eval=FALSE}
      t.test(lalonde_overlap$age[which(blocks==1)]~
               lalonde_overlap$treat[which(blocks==1)])
      t.test(lalonde_overlap$re74[which(blocks==1)]~
               lalonde_overlap$treat[which(blocks==1)])
      t.test(lalonde_overlap$age[which(blocks==2)]~
               lalonde_overlap$treat[which(blocks==2)])
      t.test(lalonde_overlap$re74[which(blocks==2)]~
               lalonde_overlap$treat[which(blocks==2)])
      t.test(lalonde_overlap$age[which(blocks==3)]~
               lalonde_overlap$treat[which(blocks==3)])
      t.test(lalonde_overlap$re74[which(blocks==3)]~
               lalonde_overlap$treat[which(blocks==3)])
      t.test(lalonde_overlap$age[which(blocks==4)]~
               lalonde_overlap$treat[which(blocks==4)])
      t.test(lalonde_overlap$re74[which(blocks==4)]~
               lalonde_overlap$treat[which(blocks==4)])
      t.test(lalonde_overlap$age[which(blocks==5)]~
               lalonde_overlap$treat[which(blocks==5)])
      t.test(lalonde_overlap$re74[which(blocks==5)]~
               lalonde_overlap$treat[which(blocks==5)])
```
All p-values>0.05 (take my word for it!)

## Assessing balance: categorical variables
        
```{r balancecat, eval=FALSE}       
fisher.test(lalonde_overlap$black[which(blocks==1)],
            lalonde_overlap$treat[which(blocks==1)])     
fisher.test(lalonde_overlap$hisp[which(blocks==1)],
            lalonde_overlap$treat[which(blocks==1)])     
fisher.test(lalonde_overlap$married[which(blocks==1)],
            lalonde_overlap$treat[which(blocks==1)])     
fisher.test(lalonde_overlap$nodegr[which(blocks==1)],
            lalonde_overlap$treat[which(blocks==1)]) 

```   
You need to run this for all 5 levels of the blocks variables. When you run the code, you notice two things: (1) all p-values>0.05, and (2) some tests failed because everyone in the block had the same value of the characteristic -- e.g. in block 2, everyone is unmarried, without a high school degree, and non-Hispanic black. Still, the block is balanced on that factor with respect to program participation.


      
## Stage 1: Estimate the propensity score
If covariates are still unbalanced in one of the blocks, try:

1. Splitting the propensity score into more classes (e.g. K=10) and recheck balance
2. Include higher order terms or interactions in the propensity score model and repeat steps!

Note: the propensity score matching R package (`Matching`) has a built in check balance function 

## Stage 1: Overview
```{r, echo=FALSE}
knitr::include_graphics("figures/propensity_score_workflow.png")
```

## Stage 2 Option 1: Stratification
We can estimate causal effects using stratification of the propensity score (similar to the check balance procedure above!)

 1. Divide subjects into $K$ strata by the corresponding quantiles of the estimated propensity score
 2. Estimate ATE within each subclass of $e_k$ and then average by the block size.
 
 $$ \hat{\tau}^{\text{ATE}} = \sum_{k=1}^K \left\{\left(\bar{Y}_{k,1} - \bar{Y}_{k,0}\right)\right\}\frac{N_{k,1}+N_{k,0}}{N} $$
 where $N_{k,1}, N_{k,0}$ are the number of units in class $k$ under treatment and control.

Variance Estimation:
$$ \mathbb{V}(\hat{\tau}) = \sum_{k=1}^K \{\mathbb{V}(\bar{Y}_{k,1}) - \mathbb{V}(\bar{Y}_{k,0})\}\left(\frac{N_{k,1}+N_{k,0}}{N}\right)^2 $$
 

## Stage 2 Option 2: Matching
In propensity score matching, the distance metric between observations is the estimated propensity score.

  * Idea is to find a treated and control patient with very similar propensity scores 
  * Do this for all treated patients and then find the average difference of their outcomes

We can use the `Matching` package in R. Just input the outcome, treated variable, and estimated propensity score. 

## Matching

```{r matching, message=FALSE}
match1 <- Match(Y=lalonde_overlap$re78, Tr = lalonde_overlap$treat, X = ps_overlap, 
      version='fast', estimand="ATE")
summary(match1)
```

In this analysis, which matches participants on potential confounders including having a high school diploma, we see again that those in the program had higher incomes than those without.

## Matching

We then can verify the resulting balance between treated and control across covariates with `MatchBalance`

```{r, eval=FALSE}
mb <- MatchBalance(treat ~ age+black+hisp+married+nodegr+re74, 
  data= lalonde_overlap,match.out=match1)

```

This code's output is suppressed due to its length, but you can run it on your own and verify the p-values for the bootstrap KS test (preferred over the t-test due to better behavior for non-continuous distributions) are all large. 

## Next steps

Using the vital records data and assuming no unmeasured confounders (a big assumption as we do not have many), start your evaluation of the causal effect of smoking on birth weight.
 

